name: Provision

on:
  push:
    branches: [ master ]
  pull_request:
    branches: [ master ]
  merge_group:
  workflow_dispatch:

jobs:
  #  check_if_website_needs_rebuilding:
  #   # runs-on: ubuntu-latest
  #   runs-on: gh-arc-runners-small
  #   outputs:
  #     needs_rebuilding: ${{ steps.changed-files.outputs.any_modified == 'true' || github.ref_name == 'master' }}
  #   steps:
  #   - uses: actions/checkout@v3
  #   - run: ./scripts/print-system-info.sh
  #   - name: Get changed files
  #     id: changed-files
  #     uses: tj-actions/changed-files@v18.6
  #     with:
  #       files: |
  #         directory/hosts/host-config.yml
  #         directory/affiliations/affiliation.schema.json
  #         website/**
  #         outputs/**
  #         .github/workflows/provision.yml
  #   - name: Debug
  #     run: |
  #       echo "===== steps.changed-files"
  #       echo '${{ toJSON(steps.changed-files) }}'

  test_website:
    # runs-on: ubuntu-latest
    runs-on: gh-arc-runners-medium
    steps:
    - uses: actions/checkout@v4
      with:
        # Fetch all branches so we can generate fixtures
        fetch-depth: 0
    - run: ./scripts/print-system-info.sh
    - uses: actions/setup-node@v3
      with:
        node-version: '20'
        cache: 'npm'
        cache-dependency-path: website/package-lock.json
    - name: Install dependencies
      working-directory: website
      run: |
        pip install -r requirements.txt
        npm ci
    - name: Test
      working-directory: website
      run: npm run test

  build_website:
    # runs-on: ubuntu-latest
    runs-on: gh-arc-runners-xlarge
    env:
      # Enable source map uploads to Sentry
      WATCLOUD_WEBSITE_SENTRY_ORG: ${{ vars.WATCLOUD_WEBSITE_SENTRY_ORG }}
      WATCLOUD_WEBSITE_SENTRY_PROJECT: ${{ vars.WATCLOUD_WEBSITE_SENTRY_PROJECT }}
      WATCLOUD_WEBSITE_SENTRY_AUTH_TOKEN: ${{ secrets.WATCLOUD_WEBSITE_SENTRY_AUTH_TOKEN }}
    steps:
    # Check out the current branch
    - uses: actions/checkout@v4
      with:
        # Fetch all branches and history so Nextra can generate modification times
        # and we can access origin/data to generate fixtures
        fetch-depth: 0
    - run: ./scripts/print-system-info.sh
    - uses: actions/setup-node@v3
      with:
        node-version: '20'
    - name: Debug - print github
      run: |
        cat << OBJECT
        ${{ toJson(github) }}
        OBJECT
    - if: github.ref_name == 'master'
      name: Set WEBSITE_BASE_PATH (master branch)
      run: |
        # Extract the path after the domain name: https://unix.stackexchange.com/a/13472
        __homepage=$(echo "${{ github.event.pull_request.head.repo.homepage || github.event.repository.homepage }}" | grep -Po 'https?:\/\/[^\/]+\K\/?.*')
        echo "WEBSITE_BASE_PATH=${__homepage%/}" >> $GITHUB_ENV
    - if: github.ref_name != 'master'
      name: Set WEBSITE_BASE_PATH (preview)
      run: |
        # Extract the path after the domain name: https://unix.stackexchange.com/a/13472
        __homepage=$(echo "$PREVIEW_WEBSITE_BASE_PATH" | grep -Po 'https?:\/\/[^\/]+\K\/?.*')
        echo "WEBSITE_BASE_PATH=${__homepage%/}/pr-${{ github.event.pull_request.number }}/${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }}/website" >> $GITHUB_ENV
    - name: Build
      run: |
        cd website
        pip install -r requirements.txt
        npm ci
        ANALYZE=true npm run build
        tar -czf out.tar.gz out
        tar -czf analyze.tar.gz -C .next analyze
    - name: Upload build output
      run: |
        pip install s3cmd
        cat > /tmp/s3cfg <<EOF
          $S3CMD_CONFIG
        EOF
        for __file in website/out.tar.gz website/analyze.tar.gz; do
          s3cmd --config=/tmp/s3cfg --acl-public put "$__file" "${S3_TMP_BASE_PATH}/website/"
          echo "External URL of the object is: ${S3_TMP_PUBLIC_HTTP_BASE_PATH}/website/$(basename $__file)"
        done

  deploy_website_prod:
    # runs-on: ubuntu-latest
    runs-on: gh-arc-runners-small
    if: github.ref_name == 'master'
    needs: [build_website]
    concurrency: deploy_website_prod_concurrency_group
    permissions:
      # required for pushing to the gh-pages branch
      contents: write
    steps:
      - uses: actions/checkout@v3
      - run: ./scripts/print-system-info.sh
      - name: Download build output
        run: wget --quiet "${S3_TMP_HTTP_BASE_PATH}/website/out.tar.gz" -O website/out.tar.gz
      - name: Extract build output
        run: tar -xzf website/out.tar.gz -C website/
      - name: Create symlinks to other deployments
        run: |
          cat .github/gh-pages-symlinks.txt | grep -v "^[[:space:]]*#" | while read -r line; do
            __from=$(echo $line | awk -F' -> ' '{print $1}')
            __to=$(echo $line | awk -F' -> ' '{print $2}')
            ln --symbolic --no-target-directory "$__to" "website/out/$__from"
          done
      - name: Set up mutex
        uses: ben-z/gh-action-mutex@v1.0-alpha-4
        with:
          branch: mutex-gh-pages
      - name: Deploy
        uses: JamesIves/github-pages-deploy-action@v4.5.0
        with:
          branch: gh-pages
          folder: website/out
          clean-exclude: |
            previews/*
            _deployments/*
          force: false

  deploy_website_preview:
    # runs-on: ubuntu-latest
    runs-on: gh-arc-runners-small
    if: github.event_name == 'pull_request'
    needs: [build_website]
    permissions:
      contents: read
      # required for creating comments on pull requests
      pull-requests: write
    outputs:
      preview_url: ${{ steps.deploy_to_preview_env.outputs.preview_url }}
    steps:
      - uses: actions/checkout@v3
      - run: ./scripts/print-system-info.sh
      - name: Download build output
        run: wget --quiet "${S3_TMP_HTTP_BASE_PATH}/website/out.tar.gz" -O website/out.tar.gz
      - name: Extract build output
        run: tar -xzf website/out.tar.gz -C website/
      - name: Install s3cmd
        run: |
          pip install s3cmd
          cat > /tmp/s3cfg <<EOF
            $S3CMD_CONFIG
          EOF
      - name: Deploy to Preview Environment
        id: deploy_to_preview_env
        run: |
          __preview_prefix="pr-${{ github.event.pull_request.number }}"
          __preview_path="${{ github.event.pull_request.base.sha }}...${{ github.event.pull_request.head.sha }}/website/"

          # Create a redirect to the latest preview
          mkdir -p tmp/latest
          echo "${PREVIEW_LATEST_HTML}" > tmp/latest/index.html
          cat <<EOF >>tmp/latest/data.json
            {"latest_url": "../../$__preview_path"}
          EOF

          # Deploy the preview
          s3cmd --config=/tmp/s3cfg put --recursive website/out/ "${S3_PREVIEWS_BASE_PATH}/${__preview_prefix}/${__preview_path}"
          s3cmd --config=/tmp/s3cfg put --recursive tmp/latest/ "${S3_PREVIEWS_BASE_PATH}/${__preview_prefix}/latest/website/"

          __preview_msg=$( \
            echo "${PREVIEW_MESSAGE_TEMPLATE}" \
            | sed "s/<preview_name>/website/g" \
            | sed "s|<preview_url>|${PREVIEW_WEBSITE_BASE_PATH}/${__preview_prefix}/${__preview_path}|g" \
            | sed "s|<preview_latest_url>|${PREVIEW_WEBSITE_BASE_PATH}/${__preview_prefix}/latest/website/|g" \
          )
          echo "PREVIEW_MESSAGE<<EOF" >> $GITHUB_ENV
          echo "$__preview_msg" >> $GITHUB_ENV
          echo "EOF" >> $GITHUB_ENV
          # output the preview url for checking internal links
          echo "preview_url=${PREVIEW_WEBSITE_BASE_PATH}/${__preview_prefix}/${__preview_path}" >> $GITHUB_OUTPUT
      - name: Create comment
        uses: peter-evans/create-or-update-comment@v2
        with:
          issue-number: ${{ github.event.pull_request.number }}
          body: ${{ env.PREVIEW_MESSAGE }}

  check_website_internal_links:
    runs-on: gh-arc-runners-small
    needs: [build_website, deploy_website_preview]
    steps:
      - uses: actions/checkout@v3
      - name: Set up Python
        uses: actions/setup-python@v3
        with:
          python-version: "3.10"
      - name: Install Python dependencies
        run: |
          cd website
          python3 -m pip install --upgrade pip
          pip install -r requirements.txt
      - name: Check for broken internal links on preview site
        run: |
          python3 website/scripts/validate-internal-links.py "${{ needs.deploy_website_preview.outputs.preview_url }}"

  push_website_code:
    runs-on: gh-arc-runners-medium
    if: github.ref_name == 'master'
    needs:
      # Make sure the website builds
      - build_website
      - build_docker_image
    steps:
      - uses: actions/checkout@v3
      - run: ./scripts/print-system-info.sh
      - uses: actions/checkout@v3
        with:
          fetch-depth: 0
          path: tmp/website
      - name: Set up secrets
        env:
          ANSIBLE_VAULT_PASSWORD: ${{ secrets.ANSIBLE_VAULT_PASSWORD }}
          ANSIBLE_VAULT_PASSWORD_FILE: ${{ runner.temp }}/ansible-vault-pass.txt
        run: |
          touch $ANSIBLE_VAULT_PASSWORD_FILE
          chmod 600 $ANSIBLE_VAULT_PASSWORD_FILE
          echo $ANSIBLE_VAULT_PASSWORD > $ANSIBLE_VAULT_PASSWORD_FILE
          export PROVISIONER_SMART_RETRIES=1

          # Download docker cache
          mkdir -p "$(dirname "${PROVISIONER_DOCKER_CACHE_PATH}")"
          wget --quiet "${S3_CACHE_HTTP_BASE_PATH}/$(basename $PROVISIONER_DOCKER_CACHE_PATH)" -O "${PROVISIONER_DOCKER_CACHE_PATH}"
          export CACHE_FROM="docker_load:${PROVISIONER_DOCKER_CACHE_PATH}"

          mkdir -p tmp
          chmod 700 tmp
          ./provision.bash script "scripts/ansible-vault-authenticate.sh 2>/dev/null && scripts/decrypt-secret.sh watcloud_website_repo_deploy_key_priv" > tmp/watcloud-website-deploy-key
          chmod 600 tmp/watcloud-website-deploy-key
      - name: Push website code
        run: |
          export GIT_SSH_COMMAND="ssh -i ../../tmp/watcloud-website-deploy-key -o IdentitiesOnly=yes -o UserKnownHostsFile=/dev/null -o StrictHostKeyChecking=no"

          pip install git-filter-repo
          cd tmp/website
          git filter-repo --subdirectory-filter website --force
          git status
          git log -2
          git remote add origin git@github.com:WATonomous/watcloud-website.git
          git remote -v
          git status
          git fetch origin
          git log -2 origin/master
          git push --set-upstream origin master
          cd ../..
      - name: Clean up
        run: rm -rf tmp